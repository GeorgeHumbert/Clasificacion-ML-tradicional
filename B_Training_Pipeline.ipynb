{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91fd8d1d-4bf5-4534-a985-2bc39b372906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1047704\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Cargar la API Key desde el archivo .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"HOPSWORKS_API_KEY\")\n",
    "\n",
    "# Conectar a Hopsworks\n",
    "project = hopsworks.login(api_key_value=api_key)\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# Obtener el Feature Group titanic_features_updated\n",
    "titanic_fg = fs.get_feature_group(name=\"titanic_features_updated\", version=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ac7f03-cfe1-423b-902f-bc6f1ae19c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.21s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>familysize</th>\n",
       "      <th>embarked_c</th>\n",
       "      <th>embarked_q</th>\n",
       "      <th>embarked_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>866</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Bystrom, Mrs. (Karolina)</td>\n",
       "      <td>1</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236852</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>726</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Oreskovic, Mr. Luka</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315094</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Smiljanic, Mr. Mile</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315037</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>587</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Jarvis, Mr. John Denzil</td>\n",
       "      <td>0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>237565</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>848</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Markoff, Mr. Marin</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349213</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  survived  pclass                      name  sex        age  \\\n",
       "0          866         1       2  Bystrom, Mrs. (Karolina)    1  42.000000   \n",
       "1          726         0       3       Oreskovic, Mr. Luka    0  20.000000   \n",
       "2          159         0       3       Smiljanic, Mr. Mile    0  29.699118   \n",
       "3          587         0       2   Jarvis, Mr. John Denzil    0  47.000000   \n",
       "4          848         0       3        Markoff, Mr. Marin    0  35.000000   \n",
       "\n",
       "   sibsp  parch  ticket     fare  familysize  embarked_c  embarked_q  \\\n",
       "0      0      0  236852  13.0000           1       False       False   \n",
       "1      0      0  315094   8.6625           1       False       False   \n",
       "2      0      0  315037   8.6625           1       False       False   \n",
       "3      0      0  237565  15.0000           1       False       False   \n",
       "4      0      0  349213   7.8958           1        True       False   \n",
       "\n",
       "   embarked_s  \n",
       "0        True  \n",
       "1        True  \n",
       "2        True  \n",
       "3        True  \n",
       "4       False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar las características desde el Feature Store\n",
    "features = titanic_fg.read()\n",
    "\n",
    "# Mostrar las primeras filas para verificar que los datos han sido cargados correctamente\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76666604-c9d0-4a1f-8c7f-78f258085197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir las características (X) y la variable objetivo (y)\n",
    "X = features.drop(columns=['survived'])  # Eliminar la columna objetivo\n",
    "y = features['survived']  # Variable objetivo\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f00e7556-6f3d-4758-a851-e72684d092a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:07<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 277, number of negative: 435\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 923\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389045 -> initscore=-0.451329\n",
      "[LightGBM] [Info] Start training from score -0.451329\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Accuracy, Balanced Accuracy, ROC AUC, F1 Score, Time Taken]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "# Crear el LazyClassifier\n",
    "clf = LazyClassifier()\n",
    "\n",
    "# Entrenar los modelos\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Mostrar los resultados de los modelos\n",
    "models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed1e5688-1459-4b26-b74c-21a3b397258b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Accuracy, Balanced Accuracy, ROC AUC, F1 Score, Time Taken]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordenar los modelos por Accuracy o F1 Score (elige la métrica que prefieras)\n",
    "best_model = models.sort_values(by='Accuracy', ascending=False).head(1)\n",
    "\n",
    "# Mostrar el mejor modelo\n",
    "best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ec8895c-3f53-49ce-bc87-2ce2233ee91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331    1\n",
       "733    0\n",
       "382    1\n",
       "704    0\n",
       "813    0\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()\n",
    "y_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98f47219-c203-490b-9a70-0c0ee7c5719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['passengerid', 'pclass', 'name', 'sex', 'age', 'sibsp', 'parch',\n",
      "       'ticket', 'fare', 'familysize', 'embarked_c', 'embarked_q',\n",
      "       'embarked_s'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fa5d7ba-908c-4309-8832-b732a8de8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['Name', 'Ticket'], errors='ignore')\n",
    "X_test = X_test.drop(columns=['Name', 'Ticket'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9e3584c-90e8-4b08-a5e2-6f8074021cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Verificar si hay columnas categóricas y usar get_dummies\n",
    "X_train = pd.get_dummies(X_train, columns=['sex', 'embarked_c', 'embarked_q', 'embarked_s'])\n",
    "X_test = pd.get_dummies(X_test, columns=['sex', 'embarked_c', 'embarked_q', 'embarked_s'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e303e22-6a3c-4bf5-9a09-f607bfb48844",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['name', 'ticket'], errors='ignore')\n",
    "X_test = X_test.drop(columns=['name', 'ticket'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10409a7f-6396-4b84-a16a-e77f16e85ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo de Regresión Logística: 0.8156424581005587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86       114\n",
      "           1       0.75      0.74      0.74        65\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.80      0.80      0.80       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Entrenar un modelo de Regresión Logística\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Accuracy del modelo de Regresión Logística:\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(classification_report(y_test, y_pred_logreg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69b29449-4795-4c1f-bd29-99fb559d2d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo Random Forest: 0.8156424581005587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86       114\n",
      "           1       0.75      0.74      0.74        65\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.80      0.80      0.80       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n",
      "\n",
      "Accuracy del modelo SVM: 0.659217877094972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.97      0.78       114\n",
      "           1       0.70      0.11      0.19        65\n",
      "\n",
      "    accuracy                           0.66       179\n",
      "   macro avg       0.68      0.54      0.49       179\n",
      "weighted avg       0.67      0.66      0.57       179\n",
      "\n",
      "\n",
      "Accuracy del modelo KNN: 0.6089385474860335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.71       114\n",
      "           1       0.45      0.34      0.39        65\n",
      "\n",
      "    accuracy                           0.61       179\n",
      "   macro avg       0.56      0.55      0.55       179\n",
      "weighted avg       0.59      0.61      0.59       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Entrenar un modelo de Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"Accuracy del modelo Random Forest:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Entrenar un modelo de SVM\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "print(\"\\nAccuracy del modelo SVM:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Entrenar un modelo de K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(\"\\nAccuracy del modelo KNN:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd5ae6c9-b8ff-4ba1-860c-4827a9429e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Mejores hiperparámetros:  {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Accuracy del mejor modelo de Random Forest optimizado: 0.8212290502793296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       114\n",
      "           1       0.77      0.72      0.75        65\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir el modelo de Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definir el espacio de búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV con validación cruzada\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "\n",
    "# Entrenar GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros encontrados\n",
    "print(\"Mejores hiperparámetros: \", grid_search.best_params_)\n",
    "\n",
    "# Evaluar el mejor modelo en los datos de prueba\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Mostrar el reporte de clasificación\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Accuracy del mejor modelo de Random Forest optimizado:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88a934e0-b608-4e29-b3ca-8c5659fa9a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelo_random_forest_optimizado.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el modelo entrenado en un archivo\n",
    "joblib.dump(best_rf, 'modelo_random_forest_optimizado.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a65ddd95-0247-4ce4-9f5c-f2ad5ddf7c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: [1]\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo guardado\n",
    "modelo_cargado = joblib.load('modelo_random_forest_optimizado.pkl')\n",
    "\n",
    "# Crear un pipeline de preprocesamiento y predicción\n",
    "def predecir(datos_nuevos):\n",
    "    # Convertir las columnas categóricas a True/False en lugar de 1/0\n",
    "    datos_nuevos['sex'] = datos_nuevos['sex'].map({0: False, 1: True})\n",
    "    datos_nuevos['embarked_c'] = datos_nuevos['embarked_c'].map({0: False, 1: True})\n",
    "    datos_nuevos['embarked_q'] = datos_nuevos['embarked_q'].map({0: False, 1: True})\n",
    "    datos_nuevos['embarked_s'] = datos_nuevos['embarked_s'].map({0: False, 1: True})\n",
    "    \n",
    "    # Asegurarse de que las columnas coincidan con las del entrenamiento\n",
    "    datos_nuevos = pd.get_dummies(datos_nuevos, columns=['sex', 'embarked_c', 'embarked_q', 'embarked_s'])\n",
    "    \n",
    "    # Rellenar las columnas faltantes con ceros para coincidir con las columnas del modelo entrenado\n",
    "    columnas_entrenamiento = modelo_cargado.feature_names_in_  # Asegúrate de que esto sea compatible con tu modelo\n",
    "    datos_nuevos = datos_nuevos.reindex(columns=columnas_entrenamiento, fill_value=0)\n",
    "    \n",
    "    # Realizar la predicción\n",
    "    prediccion = modelo_cargado.predict(datos_nuevos)\n",
    "    \n",
    "    return prediccion\n",
    "\n",
    "# Ejemplo de uso con datos nuevos\n",
    "datos_nuevos = pd.DataFrame({\n",
    "    'pclass': [1],\n",
    "    'sex': [0],  # Aquí 0 para 'male', que se mapeará a False\n",
    "    'age': [29],\n",
    "    'sibsp': [1],\n",
    "    'parch': [0],\n",
    "    'fare': [50],\n",
    "    'familysize': [1],\n",
    "    'embarked_c': [1],  # Se mapeará a True\n",
    "    'embarked_q': [0],  # Se mapeará a False\n",
    "    'embarked_s': [0]   # Se mapeará a False\n",
    "})\n",
    "\n",
    "# Obtener la predicción\n",
    "prediccion = predecir(datos_nuevos)\n",
    "print(f\"Predicción: {prediccion}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2818da25-ea09-4c31-ba69-fd7c7c48b137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
